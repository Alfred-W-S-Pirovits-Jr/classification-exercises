{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fdf4dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pydataset import data\n",
    "import acquire\n",
    "import prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6015b189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>445.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "      <td>0.602694</td>\n",
       "      <td>0.647587</td>\n",
       "      <td>0.086420</td>\n",
       "      <td>0.722783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>0.489615</td>\n",
       "      <td>0.477990</td>\n",
       "      <td>0.281141</td>\n",
       "      <td>0.447876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>222.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>445.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>667.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>890.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       passenger_id    survived      pclass         age       sibsp  \\\n",
       "count    891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean     445.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std      257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min        0.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%      222.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%      445.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%      667.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max      890.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            parch        fare       alone    sex_male  embark_town_Queenstown  \\\n",
       "count  891.000000  891.000000  891.000000  891.000000              891.000000   \n",
       "mean     0.381594   32.204208    0.602694    0.647587                0.086420   \n",
       "std      0.806057   49.693429    0.489615    0.477990                0.281141   \n",
       "min      0.000000    0.000000    0.000000    0.000000                0.000000   \n",
       "25%      0.000000    7.910400    0.000000    0.000000                0.000000   \n",
       "50%      0.000000   14.454200    1.000000    1.000000                0.000000   \n",
       "75%      0.000000   31.000000    1.000000    1.000000                0.000000   \n",
       "max      6.000000  512.329200    1.000000    1.000000                1.000000   \n",
       "\n",
       "       embark_town_Southampton  \n",
       "count               891.000000  \n",
       "mean                  0.722783  \n",
       "std                   0.447876  \n",
       "min                   0.000000  \n",
       "25%                   0.000000  \n",
       "50%                   1.000000  \n",
       "75%                   1.000000  \n",
       "max                   1.000000  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def prep_titanic():\n",
    "    titanic_db = acquire.get_titanic_data()\n",
    "    titanic_db = titanic_db.drop(columns=['embarked', 'class', 'deck'])\n",
    "    dummy_titanic_db = pd.get_dummies(titanic_db[['sex', 'embark_town']], dummy_na=False, drop_first = [True])#, True])\n",
    "    titanic_db = pd.concat([titanic_db, dummy_titanic_db], axis=1)\n",
    "    titanic_db = titanic_db.drop(columns=['Unnamed: 0', 'sex', 'embark_town'])\n",
    "    return titanic_db\n",
    "\n",
    "titanic = prep_titanic()\n",
    "titanic.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195a7d27",
   "metadata": {},
   "source": [
    "Create a model that includes only age, fare, and pclass. Does this model perform better than your baseline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "64919524",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = titanic.drop(columns=['passenger_id', 'sibsp', 'parch', 'alone', 'sex_male', 'embark_town_Queenstown', 'embark_town_Southampton'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "159c40fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = titanic.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f48f2e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.406162</td>\n",
       "      <td>2.236695</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>34.694514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.491460</td>\n",
       "      <td>0.838250</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>52.918930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>8.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>15.741700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>33.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         survived      pclass         age        fare\n",
       "count  714.000000  714.000000  714.000000  714.000000\n",
       "mean     0.406162    2.236695   29.699118   34.694514\n",
       "std      0.491460    0.838250   14.526497   52.918930\n",
       "min      0.000000    1.000000    0.420000    0.000000\n",
       "25%      0.000000    1.000000   20.125000    8.050000\n",
       "50%      0.000000    2.000000   28.000000   15.741700\n",
       "75%      1.000000    3.000000   38.000000   33.375000\n",
       "max      1.000000    3.000000   80.000000  512.329200"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0c2f3f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = prepare.split_data(titanic, 'survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9b42b317",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=['survived'])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=['survived'])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=['survived'])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "655552d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression(C=1, random_state=823, intercept_scaling=1, solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bb318a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=1, random_state=823)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1, random_state=823)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=1, random_state=823)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3ae7809f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-1.03653957e+00 -3.24465365e-02  7.12689413e-04]]\n",
      "Intercept: \n",
      " [2.82618957]\n"
     ]
    }
   ],
   "source": [
    "print('Coefficient: \\n', logit.coef_)\n",
    "print('Intercept: \\n', logit.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4178b1e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.35467991, 0.96807421, 1.00071294]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odds = np.exp(logit.coef_)\n",
    "odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cc43130c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logit.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6f48bd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = logit.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e5e9e27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on training set: 0.68\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b0ec2e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[208  46]\n",
      " [ 91  83]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "207cfdae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.82      0.75       254\n",
      "           1       0.64      0.48      0.55       174\n",
      "\n",
      "    accuracy                           0.68       428\n",
      "   macro avg       0.67      0.65      0.65       428\n",
      "weighted avg       0.67      0.68      0.67       428\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7dd65b",
   "metadata": {},
   "source": [
    "Include sex in your model as well. Note that you'll need to encode or create a dummy variable of this feature before including it in a model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fd894ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>447.582633</td>\n",
       "      <td>0.406162</td>\n",
       "      <td>2.236695</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.512605</td>\n",
       "      <td>0.431373</td>\n",
       "      <td>34.694514</td>\n",
       "      <td>0.565826</td>\n",
       "      <td>0.634454</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.775910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>259.119524</td>\n",
       "      <td>0.491460</td>\n",
       "      <td>0.838250</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>0.929783</td>\n",
       "      <td>0.853289</td>\n",
       "      <td>52.918930</td>\n",
       "      <td>0.495995</td>\n",
       "      <td>0.481921</td>\n",
       "      <td>0.194244</td>\n",
       "      <td>0.417274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>221.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>444.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.741700</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>676.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>33.375000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>890.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       passenger_id    survived      pclass         age       sibsp  \\\n",
       "count    714.000000  714.000000  714.000000  714.000000  714.000000   \n",
       "mean     447.582633    0.406162    2.236695   29.699118    0.512605   \n",
       "std      259.119524    0.491460    0.838250   14.526497    0.929783   \n",
       "min        0.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%      221.250000    0.000000    1.000000   20.125000    0.000000   \n",
       "50%      444.000000    0.000000    2.000000   28.000000    0.000000   \n",
       "75%      676.750000    1.000000    3.000000   38.000000    1.000000   \n",
       "max      890.000000    1.000000    3.000000   80.000000    5.000000   \n",
       "\n",
       "            parch        fare       alone    sex_male  embark_town_Queenstown  \\\n",
       "count  714.000000  714.000000  714.000000  714.000000              714.000000   \n",
       "mean     0.431373   34.694514    0.565826    0.634454                0.039216   \n",
       "std      0.853289   52.918930    0.495995    0.481921                0.194244   \n",
       "min      0.000000    0.000000    0.000000    0.000000                0.000000   \n",
       "25%      0.000000    8.050000    0.000000    0.000000                0.000000   \n",
       "50%      0.000000   15.741700    1.000000    1.000000                0.000000   \n",
       "75%      1.000000   33.375000    1.000000    1.000000                0.000000   \n",
       "max      6.000000  512.329200    1.000000    1.000000                1.000000   \n",
       "\n",
       "       embark_town_Southampton  \n",
       "count               714.000000  \n",
       "mean                  0.775910  \n",
       "std                   0.417274  \n",
       "min                   0.000000  \n",
       "25%                   1.000000  \n",
       "50%                   1.000000  \n",
       "75%                   1.000000  \n",
       "max                   1.000000  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic = prep_titanic()\n",
    "titanic = titanic.dropna()\n",
    "titanic.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8807e828",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = titanic.drop(columns=['passenger_id', 'sibsp', 'parch', 'alone', 'embark_town_Queenstown', 'embark_town_Southampton'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ce4417bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = prepare.split_data(titanic, 'survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7d271f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=['survived'])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=['survived'])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=['survived'])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "bec63492",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression(C=10, random_state=823, intercept_scaling=1, solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1752c99f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=10, random_state=823)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=10, random_state=823)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=10, random_state=823)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a77c3806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-1.18092589e+00 -2.81775488e-02 -1.15520026e-03 -2.90455383e+00]]\n",
      "Intercept: \n",
      " [4.81081415]\n"
     ]
    }
   ],
   "source": [
    "print('Coefficient: \\n', logit.coef_)\n",
    "print('Intercept: \\n', logit.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9044f94a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.30699436, 0.97221574, 0.99884547, 0.05477322]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odds = np.exp(logit.coef_)\n",
    "odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "902ab480",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logit.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ffe022aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = logit.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1dba9e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on training set: 0.82\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d3e9db5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[222  32]\n",
      " [ 46 128]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "fd2c71e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.87      0.85       254\n",
      "           1       0.80      0.74      0.77       174\n",
      "\n",
      "    accuracy                           0.82       428\n",
      "   macro avg       0.81      0.80      0.81       428\n",
      "weighted avg       0.82      0.82      0.82       428\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce0fcdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5063efa",
   "metadata": {},
   "source": [
    "\n",
    "Try out other combinations of features and models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "55584422",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;background-color: white;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=10, random_state=823)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=10, random_state=823)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=10, random_state=823)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all the stuff from prepare\n",
    "titanic = prep_titanic()\n",
    "titanic = titanic.dropna()\n",
    "titanic = titanic.drop(columns=['passenger_id'])\n",
    "titanic.describe()\n",
    "\n",
    "train, validate, test = prepare.split_data(titanic, 'survived')\n",
    "\n",
    "X_train = train.drop(columns=['survived'])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=['survived'])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=['survived'])\n",
    "y_test = test.survived\n",
    "\n",
    "logit = LogisticRegression(C=10, random_state=823, intercept_scaling=1, solver='lbfgs')\n",
    "\n",
    "logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e730f604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>714 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass   age  sibsp  parch     fare  alone  sex_male  \\\n",
       "0           0       3  22.0      1      0   7.2500      0         1   \n",
       "1           1       1  38.0      1      0  71.2833      0         0   \n",
       "2           1       3  26.0      0      0   7.9250      1         0   \n",
       "3           1       1  35.0      1      0  53.1000      0         0   \n",
       "4           0       3  35.0      0      0   8.0500      1         1   \n",
       "..        ...     ...   ...    ...    ...      ...    ...       ...   \n",
       "885         0       3  39.0      0      5  29.1250      0         0   \n",
       "886         0       2  27.0      0      0  13.0000      1         1   \n",
       "887         1       1  19.0      0      0  30.0000      1         0   \n",
       "889         1       1  26.0      0      0  30.0000      1         1   \n",
       "890         0       3  32.0      0      0   7.7500      1         1   \n",
       "\n",
       "     embark_town_Queenstown  embark_town_Southampton  \n",
       "0                         0                        1  \n",
       "1                         0                        0  \n",
       "2                         0                        1  \n",
       "3                         0                        1  \n",
       "4                         0                        1  \n",
       "..                      ...                      ...  \n",
       "885                       1                        0  \n",
       "886                       0                        1  \n",
       "887                       0                        1  \n",
       "889                       0                        0  \n",
       "890                       1                        0  \n",
       "\n",
       "[714 rows x 10 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "cc41bd25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-1.12507181e+00 -3.11187679e-02 -5.93575156e-01  2.43720245e-02\n",
      "   1.30290637e-03 -3.43366456e-01 -2.83117226e+00  3.90838799e-01\n",
      "   5.94576068e-01]]\n",
      "Intercept: \n",
      " [4.61997987]\n",
      "Odds: \n",
      " [[0.32462915 0.96936044 0.55234902 1.02467145 1.00130376 0.70937821\n",
      "  0.05894372 1.4782202  1.81226251]]\n"
     ]
    }
   ],
   "source": [
    "print('Coefficient: \\n', logit.coef_)\n",
    "print('Intercept: \\n', logit.intercept_)\n",
    "odds = np.exp(logit.coef_)\n",
    "print('Odds: \\n', odds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "309f24c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = logit.predict(X_train)\n",
    "y_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "f347386e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.07804646, 0.92195354],\n",
       "       [0.68733779, 0.31266221],\n",
       "       [0.93616095, 0.06383905],\n",
       "       [0.88164334, 0.11835666],\n",
       "       [0.33245121, 0.66754879],\n",
       "       [0.8997226 , 0.1002774 ],\n",
       "       [0.89414501, 0.10585499],\n",
       "       [0.88802034, 0.11197966],\n",
       "       [0.91056151, 0.08943849],\n",
       "       [0.81623015, 0.18376985],\n",
       "       [0.80935474, 0.19064526],\n",
       "       [0.73202277, 0.26797723],\n",
       "       [0.12118754, 0.87881246],\n",
       "       [0.37109478, 0.62890522],\n",
       "       [0.75523893, 0.24476107],\n",
       "       [0.08841139, 0.91158861],\n",
       "       [0.10854334, 0.89145666],\n",
       "       [0.8506704 , 0.1493296 ],\n",
       "       [0.62360778, 0.37639222],\n",
       "       [0.47907751, 0.52092249],\n",
       "       [0.39868961, 0.60131039],\n",
       "       [0.98417053, 0.01582947],\n",
       "       [0.76153756, 0.23846244],\n",
       "       [0.69535825, 0.30464175],\n",
       "       [0.2501665 , 0.7498335 ],\n",
       "       [0.05224907, 0.94775093],\n",
       "       [0.32567085, 0.67432915],\n",
       "       [0.74342801, 0.25657199],\n",
       "       [0.89296557, 0.10703443],\n",
       "       [0.86821167, 0.13178833],\n",
       "       [0.26202173, 0.73797827],\n",
       "       [0.03353943, 0.96646057],\n",
       "       [0.80326398, 0.19673602],\n",
       "       [0.09747541, 0.90252459],\n",
       "       [0.49572773, 0.50427227],\n",
       "       [0.87512002, 0.12487998],\n",
       "       [0.14279023, 0.85720977],\n",
       "       [0.39709748, 0.60290252],\n",
       "       [0.87504123, 0.12495877],\n",
       "       [0.39078113, 0.60921887],\n",
       "       [0.07621067, 0.92378933],\n",
       "       [0.11671356, 0.88328644],\n",
       "       [0.18208743, 0.81791257],\n",
       "       [0.90537896, 0.09462104],\n",
       "       [0.5622863 , 0.4377137 ],\n",
       "       [0.88417262, 0.11582738],\n",
       "       [0.73757362, 0.26242638],\n",
       "       [0.21079971, 0.78920029],\n",
       "       [0.14825157, 0.85174843],\n",
       "       [0.15084713, 0.84915287],\n",
       "       [0.86061263, 0.13938737],\n",
       "       [0.77796716, 0.22203284],\n",
       "       [0.93492352, 0.06507648],\n",
       "       [0.87168796, 0.12831204],\n",
       "       [0.3048774 , 0.6951226 ],\n",
       "       [0.2445383 , 0.7554617 ],\n",
       "       [0.90528608, 0.09471392],\n",
       "       [0.22473368, 0.77526632],\n",
       "       [0.66243204, 0.33756796],\n",
       "       [0.8576229 , 0.1423771 ],\n",
       "       [0.07477785, 0.92522215],\n",
       "       [0.04267789, 0.95732211],\n",
       "       [0.30907784, 0.69092216],\n",
       "       [0.89416504, 0.10583496],\n",
       "       [0.98511147, 0.01488853],\n",
       "       [0.52806438, 0.47193562],\n",
       "       [0.98642048, 0.01357952],\n",
       "       [0.81760085, 0.18239915],\n",
       "       [0.71455049, 0.28544951],\n",
       "       [0.74417286, 0.25582714],\n",
       "       [0.90980699, 0.09019301],\n",
       "       [0.34325095, 0.65674905],\n",
       "       [0.90668652, 0.09331348],\n",
       "       [0.06289585, 0.93710415],\n",
       "       [0.89040042, 0.10959958],\n",
       "       [0.82003508, 0.17996492],\n",
       "       [0.38269576, 0.61730424],\n",
       "       [0.55778909, 0.44221091],\n",
       "       [0.70821117, 0.29178883],\n",
       "       [0.43444116, 0.56555884],\n",
       "       [0.73757362, 0.26242638],\n",
       "       [0.31850422, 0.68149578],\n",
       "       [0.91291355, 0.08708645],\n",
       "       [0.92466063, 0.07533937],\n",
       "       [0.24374601, 0.75625399],\n",
       "       [0.7270737 , 0.2729263 ],\n",
       "       [0.26119639, 0.73880361],\n",
       "       [0.47115589, 0.52884411],\n",
       "       [0.9438495 , 0.0561505 ],\n",
       "       [0.05741029, 0.94258971],\n",
       "       [0.87174624, 0.12825376],\n",
       "       [0.69389006, 0.30610994],\n",
       "       [0.49598636, 0.50401364],\n",
       "       [0.95251309, 0.04748691],\n",
       "       [0.48045694, 0.51954306],\n",
       "       [0.62323706, 0.37676294],\n",
       "       [0.13111531, 0.86888469],\n",
       "       [0.89865365, 0.10134635],\n",
       "       [0.89217641, 0.10782359],\n",
       "       [0.87137858, 0.12862142],\n",
       "       [0.60776342, 0.39223658],\n",
       "       [0.61083108, 0.38916892],\n",
       "       [0.8997226 , 0.1002774 ],\n",
       "       [0.89992275, 0.10007725],\n",
       "       [0.86069687, 0.13930313],\n",
       "       [0.79365772, 0.20634228],\n",
       "       [0.54674461, 0.45325539],\n",
       "       [0.5861545 , 0.4138455 ],\n",
       "       [0.60763031, 0.39236969],\n",
       "       [0.04323443, 0.95676557],\n",
       "       [0.59881136, 0.40118864],\n",
       "       [0.87527077, 0.12472923],\n",
       "       [0.82280506, 0.17719494],\n",
       "       [0.90555871, 0.09444129],\n",
       "       [0.97785937, 0.02214063],\n",
       "       [0.83363906, 0.16636094],\n",
       "       [0.26686846, 0.73313154],\n",
       "       [0.16681614, 0.83318386],\n",
       "       [0.47359284, 0.52640716],\n",
       "       [0.94208658, 0.05791342],\n",
       "       [0.9526354 , 0.0473646 ],\n",
       "       [0.67572524, 0.32427476],\n",
       "       [0.09177502, 0.90822498],\n",
       "       [0.87515634, 0.12484366],\n",
       "       [0.96773936, 0.03226064],\n",
       "       [0.17126501, 0.82873499],\n",
       "       [0.65375209, 0.34624791],\n",
       "       [0.21705704, 0.78294296],\n",
       "       [0.88499866, 0.11500134],\n",
       "       [0.42552864, 0.57447136],\n",
       "       [0.95004597, 0.04995403],\n",
       "       [0.79173548, 0.20826452],\n",
       "       [0.89991589, 0.10008411],\n",
       "       [0.80569248, 0.19430752],\n",
       "       [0.30908248, 0.69091752],\n",
       "       [0.02708765, 0.97291235],\n",
       "       [0.47695945, 0.52304055],\n",
       "       [0.87850695, 0.12149305],\n",
       "       [0.73938608, 0.26061392],\n",
       "       [0.37606763, 0.62393237],\n",
       "       [0.87852434, 0.12147566],\n",
       "       [0.8881081 , 0.1118919 ],\n",
       "       [0.14043337, 0.85956663],\n",
       "       [0.93290659, 0.06709341],\n",
       "       [0.88964496, 0.11035504],\n",
       "       [0.90536175, 0.09463825],\n",
       "       [0.58012606, 0.41987394],\n",
       "       [0.04907249, 0.95092751],\n",
       "       [0.90536175, 0.09463825],\n",
       "       [0.91215086, 0.08784914],\n",
       "       [0.71277917, 0.28722083],\n",
       "       [0.69401935, 0.30598065],\n",
       "       [0.50518482, 0.49481518],\n",
       "       [0.04232922, 0.95767078],\n",
       "       [0.02460553, 0.97539447],\n",
       "       [0.05574933, 0.94425067],\n",
       "       [0.52654644, 0.47345356],\n",
       "       [0.85944804, 0.14055196],\n",
       "       [0.11172301, 0.88827699],\n",
       "       [0.71344555, 0.28655445],\n",
       "       [0.13514716, 0.86485284],\n",
       "       [0.66693305, 0.33306695],\n",
       "       [0.93118064, 0.06881936],\n",
       "       [0.44936412, 0.55063588],\n",
       "       [0.32985979, 0.67014021],\n",
       "       [0.94688148, 0.05311852],\n",
       "       [0.89416402, 0.10583598],\n",
       "       [0.03700625, 0.96299375],\n",
       "       [0.89698075, 0.10301925],\n",
       "       [0.92096082, 0.07903918],\n",
       "       [0.25373545, 0.74626455],\n",
       "       [0.09580842, 0.90419158],\n",
       "       [0.92832315, 0.07167685],\n",
       "       [0.26326523, 0.73673477],\n",
       "       [0.91052835, 0.08947165],\n",
       "       [0.71933966, 0.28066034],\n",
       "       [0.27915458, 0.72084542],\n",
       "       [0.59760546, 0.40239454],\n",
       "       [0.17749863, 0.82250137],\n",
       "       [0.8722764 , 0.1277236 ],\n",
       "       [0.35029986, 0.64970014],\n",
       "       [0.91953763, 0.08046237],\n",
       "       [0.9403342 , 0.0596658 ],\n",
       "       [0.03938473, 0.96061527],\n",
       "       [0.87852492, 0.12147508],\n",
       "       [0.31215163, 0.68784837],\n",
       "       [0.11396016, 0.88603984],\n",
       "       [0.6540821 , 0.3459179 ],\n",
       "       [0.88177243, 0.11822757],\n",
       "       [0.91918184, 0.08081816],\n",
       "       [0.71976502, 0.28023498],\n",
       "       [0.7993582 , 0.2006418 ],\n",
       "       [0.2373215 , 0.7626785 ],\n",
       "       [0.71277917, 0.28722083],\n",
       "       [0.2159824 , 0.7840176 ],\n",
       "       [0.55618161, 0.44381839],\n",
       "       [0.65298367, 0.34701633],\n",
       "       [0.09230265, 0.90769735],\n",
       "       [0.91787861, 0.08212139],\n",
       "       [0.78863574, 0.21136426],\n",
       "       [0.95234702, 0.04765298],\n",
       "       [0.30545411, 0.69454589],\n",
       "       [0.8912896 , 0.1087104 ],\n",
       "       [0.05048014, 0.94951986],\n",
       "       [0.17080319, 0.82919681],\n",
       "       [0.80057353, 0.19942647],\n",
       "       [0.97260954, 0.02739046],\n",
       "       [0.74355225, 0.25644775],\n",
       "       [0.84149624, 0.15850376],\n",
       "       [0.78809227, 0.21190773],\n",
       "       [0.05493684, 0.94506316],\n",
       "       [0.33937227, 0.66062773],\n",
       "       [0.39762849, 0.60237151],\n",
       "       [0.84381466, 0.15618534],\n",
       "       [0.81525096, 0.18474904],\n",
       "       [0.21679588, 0.78320412],\n",
       "       [0.13973599, 0.86026401],\n",
       "       [0.66004435, 0.33995565],\n",
       "       [0.93400146, 0.06599854],\n",
       "       [0.91300113, 0.08699887],\n",
       "       [0.18858556, 0.81141444],\n",
       "       [0.02928655, 0.97071345],\n",
       "       [0.93680905, 0.06319095],\n",
       "       [0.20899476, 0.79100524],\n",
       "       [0.94583421, 0.05416579],\n",
       "       [0.62186571, 0.37813429],\n",
       "       [0.33243074, 0.66756926],\n",
       "       [0.28285166, 0.71714834],\n",
       "       [0.75004378, 0.24995622],\n",
       "       [0.40342443, 0.59657557],\n",
       "       [0.89991101, 0.10008899],\n",
       "       [0.89445539, 0.10554461],\n",
       "       [0.93169188, 0.06830812],\n",
       "       [0.82890037, 0.17109963],\n",
       "       [0.16520531, 0.83479469],\n",
       "       [0.29269995, 0.70730005],\n",
       "       [0.88792023, 0.11207977],\n",
       "       [0.18244992, 0.81755008],\n",
       "       [0.13111531, 0.86888469],\n",
       "       [0.87514626, 0.12485374],\n",
       "       [0.84618625, 0.15381375],\n",
       "       [0.14595841, 0.85404159],\n",
       "       [0.08238114, 0.91761886],\n",
       "       [0.93411239, 0.06588761],\n",
       "       [0.88376164, 0.11623836],\n",
       "       [0.91057478, 0.08942522],\n",
       "       [0.19832186, 0.80167814],\n",
       "       [0.61083108, 0.38916892],\n",
       "       [0.89707302, 0.10292698],\n",
       "       [0.77995561, 0.22004439],\n",
       "       [0.61772085, 0.38227915],\n",
       "       [0.88180696, 0.11819304],\n",
       "       [0.09490685, 0.90509315],\n",
       "       [0.93787009, 0.06212991],\n",
       "       [0.8558036 , 0.1441964 ],\n",
       "       [0.07621067, 0.92378933],\n",
       "       [0.96514797, 0.03485203],\n",
       "       [0.87843625, 0.12156375],\n",
       "       [0.92020873, 0.07979127],\n",
       "       [0.20108682, 0.79891318],\n",
       "       [0.78340198, 0.21659802],\n",
       "       [0.91565877, 0.08434123],\n",
       "       [0.89766476, 0.10233524],\n",
       "       [0.53457083, 0.46542917],\n",
       "       [0.97421968, 0.02578032],\n",
       "       [0.97411478, 0.02588522],\n",
       "       [0.3023955 , 0.6976045 ],\n",
       "       [0.61111862, 0.38888138],\n",
       "       [0.21033727, 0.78966273],\n",
       "       [0.10517551, 0.89482449],\n",
       "       [0.86111285, 0.13888715],\n",
       "       [0.97211968, 0.02788032],\n",
       "       [0.5741214 , 0.4258786 ],\n",
       "       [0.87167218, 0.12832782],\n",
       "       [0.5664957 , 0.4335043 ],\n",
       "       [0.44551728, 0.55448272],\n",
       "       [0.10543772, 0.89456228],\n",
       "       [0.1502959 , 0.8497041 ],\n",
       "       [0.12176499, 0.87823501],\n",
       "       [0.67866145, 0.32133855],\n",
       "       [0.44834388, 0.55165612],\n",
       "       [0.88184429, 0.11815571],\n",
       "       [0.66772114, 0.33227886],\n",
       "       [0.17979928, 0.82020072],\n",
       "       [0.66687926, 0.33312074],\n",
       "       [0.18048195, 0.81951805],\n",
       "       [0.54266601, 0.45733399],\n",
       "       [0.86447085, 0.13552915],\n",
       "       [0.922633  , 0.077367  ],\n",
       "       [0.87171043, 0.12828957],\n",
       "       [0.89118278, 0.10881722],\n",
       "       [0.88482229, 0.11517771],\n",
       "       [0.95009336, 0.04990664],\n",
       "       [0.09235629, 0.90764371],\n",
       "       [0.8606526 , 0.1393474 ],\n",
       "       [0.86812966, 0.13187034],\n",
       "       [0.90266159, 0.09733841],\n",
       "       [0.16004917, 0.83995083],\n",
       "       [0.91550225, 0.08449775],\n",
       "       [0.91797677, 0.08202323],\n",
       "       [0.41260376, 0.58739624],\n",
       "       [0.67310488, 0.32689512],\n",
       "       [0.88822565, 0.11177435],\n",
       "       [0.02490927, 0.97509073],\n",
       "       [0.97716811, 0.02283189],\n",
       "       [0.83667245, 0.16332755],\n",
       "       [0.91309207, 0.08690793],\n",
       "       [0.25529953, 0.74470047],\n",
       "       [0.41166872, 0.58833128],\n",
       "       [0.29891976, 0.70108024],\n",
       "       [0.81760085, 0.18239915],\n",
       "       [0.32521927, 0.67478073],\n",
       "       [0.88500418, 0.11499582],\n",
       "       [0.86816694, 0.13183306],\n",
       "       [0.87487255, 0.12512745],\n",
       "       [0.89141095, 0.10858905],\n",
       "       [0.79971914, 0.20028086],\n",
       "       [0.73298955, 0.26701045],\n",
       "       [0.25685423, 0.74314577],\n",
       "       [0.78343823, 0.21656177],\n",
       "       [0.68733779, 0.31266221],\n",
       "       [0.0509191 , 0.9490809 ],\n",
       "       [0.35852345, 0.64147655],\n",
       "       [0.91550225, 0.08449775],\n",
       "       [0.89818108, 0.10181892],\n",
       "       [0.92679744, 0.07320256],\n",
       "       [0.8785168 , 0.1214832 ],\n",
       "       [0.95434805, 0.04565195],\n",
       "       [0.17689085, 0.82310915],\n",
       "       [0.12084681, 0.87915319],\n",
       "       [0.97647106, 0.02352894],\n",
       "       [0.79680495, 0.20319505],\n",
       "       [0.588506  , 0.411494  ],\n",
       "       [0.23812393, 0.76187607],\n",
       "       [0.86490767, 0.13509233],\n",
       "       [0.75523893, 0.24476107],\n",
       "       [0.60458114, 0.39541886],\n",
       "       [0.89338653, 0.10661347],\n",
       "       [0.073225  , 0.926775  ],\n",
       "       [0.86087902, 0.13912098],\n",
       "       [0.46310771, 0.53689229],\n",
       "       [0.89121383, 0.10878617],\n",
       "       [0.44143279, 0.55856721],\n",
       "       [0.03266148, 0.96733852],\n",
       "       [0.90944013, 0.09055987],\n",
       "       [0.92679744, 0.07320256],\n",
       "       [0.63980097, 0.36019903],\n",
       "       [0.92400101, 0.07599899],\n",
       "       [0.96177593, 0.03822407],\n",
       "       [0.16341804, 0.83658196],\n",
       "       [0.87074508, 0.12925492],\n",
       "       [0.16287383, 0.83712617],\n",
       "       [0.23244329, 0.76755671],\n",
       "       [0.85952671, 0.14047329],\n",
       "       [0.09227233, 0.90772767],\n",
       "       [0.20937325, 0.79062675],\n",
       "       [0.13938343, 0.86061657],\n",
       "       [0.15388879, 0.84611121],\n",
       "       [0.0367796 , 0.9632204 ],\n",
       "       [0.06852013, 0.93147987],\n",
       "       [0.36758162, 0.63241838],\n",
       "       [0.23124904, 0.76875096],\n",
       "       [0.88179338, 0.11820662],\n",
       "       [0.30559233, 0.69440767],\n",
       "       [0.72697681, 0.27302319],\n",
       "       [0.29216648, 0.70783352],\n",
       "       [0.93097634, 0.06902366],\n",
       "       [0.96511031, 0.03488969],\n",
       "       [0.87496107, 0.12503893],\n",
       "       [0.89417891, 0.10582109],\n",
       "       [0.84170968, 0.15829032],\n",
       "       [0.0393941 , 0.9606059 ],\n",
       "       [0.88159574, 0.11840426],\n",
       "       [0.36783277, 0.63216723],\n",
       "       [0.94331749, 0.05668251],\n",
       "       [0.31204674, 0.68795326],\n",
       "       [0.87623009, 0.12376991],\n",
       "       [0.0703892 , 0.9296108 ],\n",
       "       [0.72064298, 0.27935702],\n",
       "       [0.91787861, 0.08212139],\n",
       "       [0.44270936, 0.55729064],\n",
       "       [0.84968657, 0.15031343],\n",
       "       [0.88188105, 0.11811895],\n",
       "       [0.37295372, 0.62704628],\n",
       "       [0.14595841, 0.85404159],\n",
       "       [0.71277917, 0.28722083],\n",
       "       [0.17375429, 0.82624571],\n",
       "       [0.68032827, 0.31967173],\n",
       "       [0.68032827, 0.31967173],\n",
       "       [0.71910754, 0.28089246],\n",
       "       [0.90269307, 0.09730693],\n",
       "       [0.94367619, 0.05632381],\n",
       "       [0.16429341, 0.83570659],\n",
       "       [0.14251949, 0.85748051],\n",
       "       [0.07756244, 0.92243756],\n",
       "       [0.7876208 , 0.2123792 ],\n",
       "       [0.1471138 , 0.8528862 ],\n",
       "       [0.92585112, 0.07414888],\n",
       "       [0.88189802, 0.11810198],\n",
       "       [0.87168796, 0.12831204],\n",
       "       [0.19328299, 0.80671701],\n",
       "       [0.04566146, 0.95433854],\n",
       "       [0.87172803, 0.12827197],\n",
       "       [0.92368628, 0.07631372],\n",
       "       [0.93666785, 0.06333215],\n",
       "       [0.66251019, 0.33748981],\n",
       "       [0.07523557, 0.92476443],\n",
       "       [0.46302754, 0.53697246],\n",
       "       [0.72535021, 0.27464979],\n",
       "       [0.94552116, 0.05447884],\n",
       "       [0.2115251 , 0.7884749 ],\n",
       "       [0.87860079, 0.12139921],\n",
       "       [0.31141623, 0.68858377],\n",
       "       [0.94848849, 0.05151151],\n",
       "       [0.88188105, 0.11811895],\n",
       "       [0.88812806, 0.11187194],\n",
       "       [0.90268162, 0.09731838],\n",
       "       [0.96565217, 0.03434783],\n",
       "       [0.93554796, 0.06445204],\n",
       "       [0.32932357, 0.67067643],\n",
       "       [0.92459101, 0.07540899],\n",
       "       [0.86672409, 0.13327591],\n",
       "       [0.83931834, 0.16068166],\n",
       "       [0.54263367, 0.45736633],\n",
       "       [0.84944906, 0.15055094],\n",
       "       [0.11267889, 0.88732111],\n",
       "       [0.64038557, 0.35961443],\n",
       "       [0.63278037, 0.36721963]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba = logit.predict_proba(X_train)\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1269dfa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on training set: 0.82\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c3d5c598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[221  33]\n",
      " [ 46 128]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "e5c1af60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>221</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  221   33\n",
       "1   46  128"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "11c9c863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.87      0.85       254\n",
      "           1       0.80      0.74      0.76       174\n",
      "\n",
      "    accuracy                           0.82       428\n",
      "   macro avg       0.81      0.80      0.81       428\n",
      "weighted avg       0.81      0.82      0.81       428\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8818267c",
   "metadata": {},
   "source": [
    "Drop embark info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "a1727e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-16 {color: black;background-color: white;}#sk-container-id-16 pre{padding: 0;}#sk-container-id-16 div.sk-toggleable {background-color: white;}#sk-container-id-16 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-16 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-16 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-16 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-16 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-16 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-16 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-16 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-16 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-16 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-16 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-16 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-16 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-16 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-16 div.sk-item {position: relative;z-index: 1;}#sk-container-id-16 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-16 div.sk-item::before, #sk-container-id-16 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-16 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-16 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-16 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-16 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-16 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-16 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-16 div.sk-label-container {text-align: center;}#sk-container-id-16 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-16 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-16\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=10, random_state=823)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" checked><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=10, random_state=823)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=10, random_state=823)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic = prep_titanic()\n",
    "titanic = titanic.dropna()\n",
    "titanic = titanic.drop(columns=['passenger_id', 'embark_town_Queenstown', 'embark_town_Southampton'])\n",
    "titanic.describe()\n",
    "\n",
    "train, validate, test = prepare.split_data(titanic, 'survived')\n",
    "\n",
    "X_train = train.drop(columns=['survived'])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=['survived'])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=['survived'])\n",
    "y_test = test.survived\n",
    "\n",
    "logit = LogisticRegression(C=10, random_state=823, intercept_scaling=1, solver='lbfgs')\n",
    "\n",
    "logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "f9504a3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>714 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass   age  sibsp  parch     fare  alone  sex_male\n",
       "0           0       3  22.0      1      0   7.2500      0         1\n",
       "1           1       1  38.0      1      0  71.2833      0         0\n",
       "2           1       3  26.0      0      0   7.9250      1         0\n",
       "3           1       1  35.0      1      0  53.1000      0         0\n",
       "4           0       3  35.0      0      0   8.0500      1         1\n",
       "..        ...     ...   ...    ...    ...      ...    ...       ...\n",
       "885         0       3  39.0      0      5  29.1250      0         0\n",
       "886         0       2  27.0      0      0  13.0000      1         1\n",
       "887         1       1  19.0      0      0  30.0000      1         0\n",
       "889         1       1  26.0      0      0  30.0000      1         1\n",
       "890         0       3  32.0      0      0   7.7500      1         1\n",
       "\n",
       "[714 rows x 8 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "1185c651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-1.22087939e+00 -3.38843366e-02 -4.96454992e-01  5.30201805e-04\n",
      "  -1.11118922e-03 -4.33834390e-01 -2.95292872e+00]]\n",
      "Intercept: \n",
      " [5.61222555]\n",
      "Odds: \n",
      " [[0.29497066 0.96668331 0.60868463 1.00053034 0.99888943 0.64801957\n",
      "  0.05218664]]\n"
     ]
    }
   ],
   "source": [
    "print('Coefficient: \\n', logit.coef_)\n",
    "print('Intercept: \\n', logit.intercept_)\n",
    "odds = np.exp(logit.coef_)\n",
    "print('Odds: \\n', odds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "e7b3d6d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = logit.predict(X_train)\n",
    "y_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "874eecc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04355165, 0.95644835],\n",
       "       [0.70511308, 0.29488692],\n",
       "       [0.93916989, 0.06083011],\n",
       "       [0.89958589, 0.10041411],\n",
       "       [0.34841065, 0.65158935],\n",
       "       [0.91655952, 0.08344048],\n",
       "       [0.91109782, 0.08890218],\n",
       "       [0.91536275, 0.08463725],\n",
       "       [0.92624702, 0.07375298],\n",
       "       [0.8106623 , 0.1893377 ],\n",
       "       [0.72982025, 0.27017975],\n",
       "       [0.6502213 , 0.3497787 ],\n",
       "       [0.11780381, 0.88219619],\n",
       "       [0.39246738, 0.60753262],\n",
       "       [0.77682726, 0.22317274],\n",
       "       [0.04789421, 0.95210579],\n",
       "       [0.10443114, 0.89556886],\n",
       "       [0.85378259, 0.14621741],\n",
       "       [0.59889776, 0.40110224],\n",
       "       [0.28691907, 0.71308093],\n",
       "       [0.27867149, 0.72132851],\n",
       "       [0.9789922 , 0.0210078 ],\n",
       "       [0.78217359, 0.21782641],\n",
       "       [0.71259054, 0.28740946],\n",
       "       [0.22758842, 0.77241158],\n",
       "       [0.04413217, 0.95586783],\n",
       "       [0.21013063, 0.78986937],\n",
       "       [0.76495838, 0.23504162],\n",
       "       [0.88977831, 0.11022169],\n",
       "       [0.88652286, 0.11347714],\n",
       "       [0.23972094, 0.76027906],\n",
       "       [0.03491686, 0.96508314],\n",
       "       [0.82523571, 0.17476429],\n",
       "       [0.05538128, 0.94461872],\n",
       "       [0.41685893, 0.58314107],\n",
       "       [0.7973672 , 0.2026328 ],\n",
       "       [0.14299471, 0.85700529],\n",
       "       [0.38015273, 0.61984727],\n",
       "       [0.89326061, 0.10673939],\n",
       "       [0.26904769, 0.73095231],\n",
       "       [0.04447719, 0.95552281],\n",
       "       [0.11613617, 0.88386383],\n",
       "       [0.15943002, 0.84056998],\n",
       "       [0.92146928, 0.07853072],\n",
       "       [0.60112528, 0.39887472],\n",
       "       [0.88734633, 0.11265367],\n",
       "       [0.75870978, 0.24129022],\n",
       "       [0.17575697, 0.82424303],\n",
       "       [0.13046404, 0.86953596],\n",
       "       [0.11928555, 0.88071445],\n",
       "       [0.86079313, 0.13920687],\n",
       "       [0.69686318, 0.30313682],\n",
       "       [0.94791409, 0.05208591],\n",
       "       [0.8899199 , 0.1100801 ],\n",
       "       [0.31878388, 0.68121612],\n",
       "       [0.2066745 , 0.7933255 ],\n",
       "       [0.92984116, 0.07015884],\n",
       "       [0.23203852, 0.76796148],\n",
       "       [0.68725917, 0.31274083],\n",
       "       [0.85799289, 0.14200711],\n",
       "       [0.06810415, 0.93189585],\n",
       "       [0.04336887, 0.95663113],\n",
       "       [0.27587985, 0.72412015],\n",
       "       [0.91108319, 0.08891681],\n",
       "       [0.98034164, 0.01965836],\n",
       "       [0.39908931, 0.60091069],\n",
       "       [0.98220795, 0.01779205],\n",
       "       [0.83941528, 0.16058472],\n",
       "       [0.74230418, 0.25769582],\n",
       "       [0.76435848, 0.23564152],\n",
       "       [0.91140489, 0.08859511],\n",
       "       [0.31097389, 0.68902611],\n",
       "       [0.92269878, 0.07730122],\n",
       "       [0.08079364, 0.91920636],\n",
       "       [0.89394099, 0.10605901],\n",
       "       [0.75507986, 0.24492014],\n",
       "       [0.35498048, 0.64501952],\n",
       "       [0.54146302, 0.45853698],\n",
       "       [0.82006044, 0.17993956],\n",
       "       [0.41321726, 0.58678274],\n",
       "       [0.75870978, 0.24129022],\n",
       "       [0.33343385, 0.66656615],\n",
       "       [0.92863546, 0.07136454],\n",
       "       [0.93897781, 0.06102219],\n",
       "       [0.14452381, 0.85547619],\n",
       "       [0.75505333, 0.24494667],\n",
       "       [0.26475899, 0.73524101],\n",
       "       [0.41902968, 0.58097032],\n",
       "       [0.918982  , 0.081018  ],\n",
       "       [0.0535915 , 0.9464085 ],\n",
       "       [0.88987635, 0.11012365],\n",
       "       [0.69303991, 0.30696009],\n",
       "       [0.52546339, 0.47453661],\n",
       "       [0.94590966, 0.05409034],\n",
       "       [0.49342049, 0.50657951],\n",
       "       [0.65153295, 0.34846705],\n",
       "       [0.12909742, 0.87090258],\n",
       "       [0.89635268, 0.10364732],\n",
       "       [0.90756707, 0.09243293],\n",
       "       [0.89015055, 0.10984945],\n",
       "       [0.57864208, 0.42135792],\n",
       "       [0.63406927, 0.36593073],\n",
       "       [0.91655952, 0.08344048],\n",
       "       [0.91641458, 0.08358542],\n",
       "       [0.87969728, 0.12030272],\n",
       "       [0.70485237, 0.29514763],\n",
       "       [0.47292317, 0.52707683],\n",
       "       [0.44743597, 0.55256403],\n",
       "       [0.58111337, 0.41888663],\n",
       "       [0.02219808, 0.97780192],\n",
       "       [0.60960434, 0.39039566],\n",
       "       [0.89308965, 0.10691035],\n",
       "       [0.85062349, 0.14937651],\n",
       "       [0.90493548, 0.09506452],\n",
       "       [0.97274489, 0.02725511],\n",
       "       [0.82758613, 0.17241387],\n",
       "       [0.27360734, 0.72639266],\n",
       "       [0.17009287, 0.82990713],\n",
       "       [0.50441336, 0.49558664],\n",
       "       [0.94364628, 0.05635372],\n",
       "       [0.91914116, 0.08085884],\n",
       "       [0.55252322, 0.44747678],\n",
       "       [0.05326587, 0.94673413],\n",
       "       [0.89317494, 0.10682506],\n",
       "       [0.95923807, 0.04076193],\n",
       "       [0.17180373, 0.82819627],\n",
       "       [0.49168881, 0.50831119],\n",
       "       [0.13019096, 0.86980904],\n",
       "       [0.90249761, 0.09750239],\n",
       "       [0.50479561, 0.49520439],\n",
       "       [0.92857376, 0.07142624],\n",
       "       [0.78328232, 0.21671768],\n",
       "       [0.91641955, 0.08358045],\n",
       "       [0.80092834, 0.19907166],\n",
       "       [0.27587614, 0.72412386],\n",
       "       [0.02367448, 0.97632552],\n",
       "       [0.44819419, 0.55180581],\n",
       "       [0.89637247, 0.10362753],\n",
       "       [0.76726029, 0.23273971],\n",
       "       [0.25593144, 0.74406856],\n",
       "       [0.89635956, 0.10364044],\n",
       "       [0.90545356, 0.09454644],\n",
       "       [0.07391316, 0.92608684],\n",
       "       [0.94628332, 0.05371668],\n",
       "       [0.90689401, 0.09310599],\n",
       "       [0.92148168, 0.07851832],\n",
       "       [0.47418478, 0.52581522],\n",
       "       [0.05312887, 0.94687113],\n",
       "       [0.92148168, 0.07851832],\n",
       "       [0.91425125, 0.08574875],\n",
       "       [0.73303611, 0.26696389],\n",
       "       [0.58840059, 0.41159941],\n",
       "       [0.52511488, 0.47488512],\n",
       "       [0.06065219, 0.93934781],\n",
       "       [0.02509229, 0.97490771],\n",
       "       [0.05189868, 0.94810132],\n",
       "       [0.50797902, 0.49202098],\n",
       "       [0.88009002, 0.11990998],\n",
       "       [0.07037051, 0.92962949],\n",
       "       [0.73249212, 0.26750788],\n",
       "       [0.08389285, 0.91610715],\n",
       "       [0.68354538, 0.31645462],\n",
       "       [0.89940801, 0.10059199],\n",
       "       [0.28316702, 0.71683298],\n",
       "       [0.30503496, 0.69496504],\n",
       "       [0.95852631, 0.04147369],\n",
       "       [0.91108394, 0.08891606],\n",
       "       [0.04549217, 0.95450783],\n",
       "       [0.91385803, 0.08614197],\n",
       "       [0.93444185, 0.06555815],\n",
       "       [0.2629391 , 0.7370609 ],\n",
       "       [0.0915381 , 0.9084619 ],\n",
       "       [0.9334079 , 0.0665921 ],\n",
       "       [0.24590407, 0.75409593],\n",
       "       [0.92627074, 0.07372926],\n",
       "       [0.74993694, 0.25006306],\n",
       "       [0.2900999 , 0.7099001 ],\n",
       "       [0.4641627 , 0.5358373 ],\n",
       "       [0.15494134, 0.84505866],\n",
       "       [0.78454735, 0.21545265],\n",
       "       [0.31828036, 0.68171964],\n",
       "       [0.92173593, 0.07826407],\n",
       "       [0.89974955, 0.10025045],\n",
       "       [0.04072583, 0.95927417],\n",
       "       [0.89635913, 0.10364087],\n",
       "       [0.32562855, 0.67437145],\n",
       "       [0.08175036, 0.91824964],\n",
       "       [0.64343343, 0.35656657],\n",
       "       [0.8994905 , 0.1005095 ],\n",
       "       [0.91896994, 0.08103006],\n",
       "       [0.73907915, 0.26092085],\n",
       "       [0.71647613, 0.28352387],\n",
       "       [0.21423767, 0.78576233],\n",
       "       [0.73303611, 0.26696389],\n",
       "       [0.22917412, 0.77082588],\n",
       "       [0.54284213, 0.45715787],\n",
       "       [0.56788585, 0.43211415],\n",
       "       [0.08146421, 0.91853579],\n",
       "       [0.93289741, 0.06710259],\n",
       "       [0.80965961, 0.19034039],\n",
       "       [0.93171511, 0.06828489],\n",
       "       [0.31828036, 0.68171964],\n",
       "       [0.90822215, 0.09177785],\n",
       "       [0.05535274, 0.94464726],\n",
       "       [0.17219936, 0.82780064],\n",
       "       [0.82730928, 0.17269072],\n",
       "       [0.95642685, 0.04357315],\n",
       "       [0.76485847, 0.23514153],\n",
       "       [0.76469126, 0.23530874],\n",
       "       [0.81008736, 0.18991264],\n",
       "       [0.05064118, 0.94935882],\n",
       "       [0.35616011, 0.64383989],\n",
       "       [0.24383597, 0.75616403],\n",
       "       [0.86496908, 0.13503092],\n",
       "       [0.8115136 , 0.1884864 ],\n",
       "       [0.19383444, 0.80616556],\n",
       "       [0.13369278, 0.86630722],\n",
       "       [0.68810905, 0.31189095],\n",
       "       [0.9396835 , 0.0603165 ],\n",
       "       [0.92857315, 0.07142685],\n",
       "       [0.09757714, 0.90242286],\n",
       "       [0.02698008, 0.97301992],\n",
       "       [0.94705237, 0.05294763],\n",
       "       [0.21432582, 0.78567418],\n",
       "       [0.95678984, 0.04321016],\n",
       "       [0.65266212, 0.34733788],\n",
       "       [0.34842851, 0.65157149],\n",
       "       [0.29834007, 0.70165993],\n",
       "       [0.73170036, 0.26829964],\n",
       "       [0.28421408, 0.71578592],\n",
       "       [0.91642309, 0.08357691],\n",
       "       [0.89253806, 0.10746194],\n",
       "       [0.88242156, 0.11757844],\n",
       "       [0.82657255, 0.17342745],\n",
       "       [0.14620788, 0.85379212],\n",
       "       [0.3222505 , 0.6777495 ],\n",
       "       [0.90559141, 0.09440859],\n",
       "       [0.15363395, 0.84636605],\n",
       "       [0.12909742, 0.87090258],\n",
       "       [0.89318245, 0.10681755],\n",
       "       [0.84161161, 0.15838839],\n",
       "       [0.14511685, 0.85488315],\n",
       "       [0.07688621, 0.92311379],\n",
       "       [0.903914  , 0.096086  ],\n",
       "       [0.90295284, 0.09704716],\n",
       "       [0.92623753, 0.07376247],\n",
       "       [0.20363026, 0.79636974],\n",
       "       [0.63406927, 0.36593073],\n",
       "       [0.91379094, 0.08620906],\n",
       "       [0.80707873, 0.19292127],\n",
       "       [0.65605494, 0.34394506],\n",
       "       [0.89946496, 0.10053504],\n",
       "       [0.05795215, 0.94204785],\n",
       "       [0.91205951, 0.08794049],\n",
       "       [0.8763505 , 0.1236495 ],\n",
       "       [0.04447719, 0.95552281],\n",
       "       [0.95549448, 0.04450552],\n",
       "       [0.89642492, 0.10357508],\n",
       "       [0.93497729, 0.06502271],\n",
       "       [0.18446857, 0.81553143],\n",
       "       [0.8043828 , 0.1956172 ],\n",
       "       [0.93063348, 0.06936652],\n",
       "       [0.89673174, 0.10326826],\n",
       "       [0.45853058, 0.54146942],\n",
       "       [0.95916532, 0.04083468],\n",
       "       [0.98116929, 0.01883071],\n",
       "       [0.26922346, 0.73077654],\n",
       "       [0.65240188, 0.34759812],\n",
       "       [0.12151428, 0.87848572],\n",
       "       [0.09266286, 0.90733714],\n",
       "       [0.81095284, 0.18904716],\n",
       "       [0.97462453, 0.02537547],\n",
       "       [0.57857005, 0.42142995],\n",
       "       [0.88993169, 0.11006831],\n",
       "       [0.57028689, 0.42971311],\n",
       "       [0.27974071, 0.72025929],\n",
       "       [0.07599638, 0.92400362],\n",
       "       [0.1490186 , 0.8509814 ],\n",
       "       [0.12317318, 0.87682682],\n",
       "       [0.56459684, 0.43540316],\n",
       "       [0.43900302, 0.56099698],\n",
       "       [0.89943732, 0.10056268],\n",
       "       [0.70740215, 0.29259785],\n",
       "       [0.18207517, 0.81792483],\n",
       "       [0.52450692, 0.47549308],\n",
       "       [0.10458713, 0.89541287],\n",
       "       [0.5608133 , 0.4391867 ],\n",
       "       [0.88317385, 0.11682615],\n",
       "       [0.92345698, 0.07654302],\n",
       "       [0.88990312, 0.11009688],\n",
       "       [0.90830046, 0.09169954],\n",
       "       [0.90262751, 0.09737249],\n",
       "       [0.92851723, 0.07148277],\n",
       "       [0.08768849, 0.91231151],\n",
       "       [0.87973059, 0.12026941],\n",
       "       [0.88658433, 0.11341567],\n",
       "       [0.91899476, 0.08100524],\n",
       "       [0.13801247, 0.86198753],\n",
       "       [0.93074489, 0.06925511],\n",
       "       [0.93282782, 0.06717218],\n",
       "       [0.38374821, 0.61625179],\n",
       "       [0.72828372, 0.27171628],\n",
       "       [0.90536713, 0.09463287],\n",
       "       [0.02175437, 0.97824563],\n",
       "       [0.96415573, 0.03584427],\n",
       "       [0.83460018, 0.16539982],\n",
       "       [0.92850833, 0.07149167],\n",
       "       [0.26257168, 0.73742832],\n",
       "       [0.43748411, 0.56251589],\n",
       "       [0.31095008, 0.68904992],\n",
       "       [0.83941528, 0.16058472],\n",
       "       [0.34490855, 0.65509145],\n",
       "       [0.90249355, 0.09750645],\n",
       "       [0.88655639, 0.11344361],\n",
       "       [0.89338592, 0.10661408],\n",
       "       [0.88930569, 0.11069431],\n",
       "       [0.75867161, 0.24132839],\n",
       "       [0.70099961, 0.29900039],\n",
       "       [0.26436575, 0.73563425],\n",
       "       [0.69868677, 0.30131323],\n",
       "       [0.70511308, 0.29488692],\n",
       "       [0.05494742, 0.94505258],\n",
       "       [0.35471307, 0.64528693],\n",
       "       [0.93074489, 0.06925511],\n",
       "       [0.91765976, 0.08234024],\n",
       "       [0.9408925 , 0.0591075 ],\n",
       "       [0.89636516, 0.10363484],\n",
       "       [0.95044367, 0.04955633],\n",
       "       [0.13830882, 0.86169118],\n",
       "       [0.13806455, 0.86193545],\n",
       "       [0.97088946, 0.02911054],\n",
       "       [0.79542955, 0.20457045],\n",
       "       [0.61010877, 0.38989123],\n",
       "       [0.24622153, 0.75377847],\n",
       "       [0.88844366, 0.11155634],\n",
       "       [0.77682726, 0.22317274],\n",
       "       [0.4620171 , 0.5379829 ],\n",
       "       [0.91123373, 0.08876627],\n",
       "       [0.06193674, 0.93806326],\n",
       "       [0.87956001, 0.12043999],\n",
       "       [0.42810566, 0.57189434],\n",
       "       [0.90827771, 0.09172229],\n",
       "       [0.58666199, 0.41333801],\n",
       "       [0.04074616, 0.95925384],\n",
       "       [0.9082862 , 0.0917138 ],\n",
       "       [0.9408925 , 0.0591075 ],\n",
       "       [0.63157081, 0.36842919],\n",
       "       [0.92650599, 0.07349401],\n",
       "       [0.97100058, 0.02899942],\n",
       "       [0.09696687, 0.90303313],\n",
       "       [0.89062006, 0.10937994],\n",
       "       [0.15795124, 0.84204876],\n",
       "       [0.13199718, 0.86800282],\n",
       "       [0.88003137, 0.11996863],\n",
       "       [0.09093668, 0.90906332],\n",
       "       [0.12543187, 0.87456813],\n",
       "       [0.07716335, 0.92283665],\n",
       "       [0.1537279 , 0.8462721 ],\n",
       "       [0.03597725, 0.96402275],\n",
       "       [0.06245418, 0.93754582],\n",
       "       [0.38800883, 0.61199117],\n",
       "       [0.21826052, 0.78173948],\n",
       "       [0.89947501, 0.10052499],\n",
       "       [0.31815982, 0.68184018],\n",
       "       [0.72372712, 0.27627288],\n",
       "       [0.3039749 , 0.6960251 ],\n",
       "       [0.94450409, 0.05549591],\n",
       "       [0.96298726, 0.03701274],\n",
       "       [0.89332019, 0.10667981],\n",
       "       [0.91107306, 0.08892694],\n",
       "       [0.83850884, 0.16149116],\n",
       "       [0.03625066, 0.96374934],\n",
       "       [0.89962102, 0.10037898],\n",
       "       [0.38779009, 0.61220991],\n",
       "       [0.93451371, 0.06548629],\n",
       "       [0.32572006, 0.67427994],\n",
       "       [0.78953347, 0.21046653],\n",
       "       [0.07291352, 0.92708648],\n",
       "       [0.66274994, 0.33725006],\n",
       "       [0.93289741, 0.06710259],\n",
       "       [0.27562659, 0.72437341],\n",
       "       [0.84967588, 0.15032412],\n",
       "       [0.8994101 , 0.1005899 ],\n",
       "       [0.34925945, 0.65074055],\n",
       "       [0.14511685, 0.85488315],\n",
       "       [0.73303611, 0.26696389],\n",
       "       [0.17838239, 0.82161761],\n",
       "       [0.6982531 , 0.3017469 ],\n",
       "       [0.6982531 , 0.3017469 ],\n",
       "       [0.7396145 , 0.2603855 ],\n",
       "       [0.91897201, 0.08102799],\n",
       "       [0.95573775, 0.04426225],\n",
       "       [0.16507445, 0.83492555],\n",
       "       [0.14062751, 0.85937249],\n",
       "       [0.065993  , 0.934007  ],\n",
       "       [0.80174234, 0.19825766],\n",
       "       [0.14311922, 0.85688078],\n",
       "       [0.92622425, 0.07377575],\n",
       "       [0.89939753, 0.10060247],\n",
       "       [0.8899199 , 0.1100801 ],\n",
       "       [0.17857183, 0.82142817],\n",
       "       [0.04792978, 0.95207022],\n",
       "       [0.88988996, 0.11011004],\n",
       "       [0.92387513, 0.07612487],\n",
       "       [0.94964698, 0.05035302],\n",
       "       [0.71256754, 0.28743246],\n",
       "       [0.09482811, 0.90517189],\n",
       "       [0.44671274, 0.55328726],\n",
       "       [0.74608694, 0.25391306],\n",
       "       [0.92141532, 0.07858468],\n",
       "       [0.20919081, 0.79080919],\n",
       "       [0.89630278, 0.10369722],\n",
       "       [0.30570192, 0.69429808],\n",
       "       [0.95980993, 0.04019007],\n",
       "       [0.8994101 , 0.1005899 ],\n",
       "       [0.90543889, 0.09456111],\n",
       "       [0.91898028, 0.08101972],\n",
       "       [0.95198068, 0.04801932],\n",
       "       [0.88927264, 0.11072736],\n",
       "       [0.29667219, 0.70332781],\n",
       "       [0.93902661, 0.06097339],\n",
       "       [0.88711521, 0.11288479],\n",
       "       [0.86122812, 0.13877188],\n",
       "       [0.56084067, 0.43915933],\n",
       "       [0.82734982, 0.17265018],\n",
       "       [0.11265148, 0.88734852],\n",
       "       [0.510694  , 0.489306  ],\n",
       "       [0.65731849, 0.34268151]])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba = logit.predict_proba(X_train)\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "1ad562e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on training set: 0.81\n",
      "[[218  36]\n",
      " [ 45 129]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>218</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  218   36\n",
       "1   45  129"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X_train, y_train)))\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "pd.DataFrame(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "a95ae579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.84       254\n",
      "           1       0.78      0.74      0.76       174\n",
      "\n",
      "    accuracy                           0.81       428\n",
      "   macro avg       0.81      0.80      0.80       428\n",
      "weighted avg       0.81      0.81      0.81       428\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc0be1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4283dfd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a0060a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba47bd9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "953beaa6",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4199409991.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[106], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    Use you best 3 models to predict and evaluate on your validate sample.\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Use you best 3 models to predict and evaluate on your validate sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a340b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Choose you best model from the validation performation, and evaluate it on the test dataset. How do the performance metrics compare to validate? to train?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75282cfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
